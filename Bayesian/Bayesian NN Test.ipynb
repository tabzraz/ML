{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "optim = tf.train.AdamOptimizer(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-banner\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1f54c798-15bb-4db8-a63a-eb971176d83b\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\") {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  var js_urls = ['https://cdn.pydata.org/bokeh/release/bokeh-0.11.1.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.11.1.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-compiler-0.11.1.min.js'];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      Bokeh.$(\"#1f54c798-15bb-4db8-a63a-eb971176d83b\").text(\"BokehJS successfully loaded\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.11.1.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.11.1.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.11.1.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.11.1.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i](window.Bokeh);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.plotting import figure, output_notebook, show\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import BayesianNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bnn = BayesianNN.BayesianFC([1,128,128,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_func(x):\n",
    "    e = np.random.normal(0,0.01)\n",
    "    return x + 0.3*np.sin(2 *np.pi * (x + e)) + 0.3*np.sin(4 * np.pi*(x + e)) + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = [(x, test_func(x)) for x in np.linspace(0,0.5,1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_input = list(map(lambda x: [x[0]], data))\n",
    "data_target = list(map(lambda x: [x[1]], data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_nn(optim):\n",
    "    data_input = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "    data_target = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "    \n",
    "    net = tflearn.fully_connected(data_input, 128, activation=\"relu\")\n",
    "    net = tflearn.fully_connected(net, 128, activation=\"relu\")\n",
    "#     net = tflearn.fully_connected(net, 32, activation=\"relu\")\n",
    "#     net = tflearn.fully_connected(net, 32, activation=\"relu\")\n",
    "#     net = tflearn.fully_connected(net, 32, activation=\"relu\")\n",
    "    \n",
    "    data_output = tflearn.fully_connected(net, 1, activation=\"linear\")\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.square(data_output - data_target))\n",
    "    op = optim.minimize(loss)\n",
    "    \n",
    "    return op, data_input, data_target, loss, data_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op, data_x, data_y, m_scaling, loss, mean_grads = bnn.update(8, optim, batch_size)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch_loss = []\n",
    "nn_epoch_loss = []\n",
    "epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# op, data_x, data_y, loss, data_output = normal_nn(optim)\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# for e in tqdm(range(epochs)):\n",
    "#     input_batch = data_input\n",
    "#     target_batch = data_target\n",
    "\n",
    "#     _, l = sess.run([op, loss], feed_dict={data_x: input_batch, data_y:target_batch})\n",
    "#     nn_epoch_loss.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1163/2000 [00:50<00:35, 23.41it/s]"
     ]
    }
   ],
   "source": [
    "for e in tqdm(range(epochs)):\n",
    "#     indices = np.random.randint(low=0, high=1000, size=100)\n",
    "#     input_batch = [data_input[i] for i in indices]\n",
    "#     target_batch = [data_target[i] for i in indices]\n",
    "    input_batch = data_input\n",
    "    target_batch = data_target\n",
    "    ms = (2**(epochs - e - 1))/( (2**epochs) - 1) \n",
    "    \n",
    "#     grad_nums = [a for (a,b) in grads]\n",
    "    _, l = sess.run([op, loss], feed_dict={data_x: input_batch, data_y:target_batch, m_scaling:[ms]})\n",
    "    epoch_loss.append(l)\n",
    "    \n",
    "#     print()\n",
    "#     print(wg)\n",
    "#     print()\n",
    "#     print(mg)\n",
    "#     print()\n",
    "#     print(sg)\n",
    "#     print()\n",
    "        \n",
    "\n",
    "#     print(\"Epoch {}:\".format(e))\n",
    "#     print(sess.run([bnn.qb_mean, bnn.qb_p]))\n",
    "#     print(g)\n",
    "#     print()\n",
    "    #     print(\"---\")\n",
    "    #     print(sess.run([bnn.qw_p, bnn.qb_p]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sess.run(bnn.qw_ps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_set = [[x] for x in np.linspace(-0.5,1,1000)]\n",
    "test_set_flat = [a[0] for a in test_set]\n",
    "data_input_flat = [a[0] for a in data_input]\n",
    "data_target_flat = [a[0] for a in data_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_input, pred_output = bnn.sample()\n",
    "predictions = sess.run(pred_output, feed_dict={pred_input: test_set})\n",
    "var_trials = 100\n",
    "for _ in tqdm(range(var_trials-1)):\n",
    "    predictions = np.concatenate([predictions, sess.run(pred_output, feed_dict={pred_input: test_set})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_means = np.apply_along_axis(lambda x: np.mean(x), 1, predictions)\n",
    "pred_means[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_vars = np.apply_along_axis(lambda x: np.std(x, ddof=1), 1, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nn_preds = sess.run(data_output, feed_dict={data_x: test_set})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = figure(width=500, height=500)\n",
    "\n",
    "err_xs=[]\n",
    "err_ys=[]\n",
    "for x, y, yerr in zip(test_set_flat, pred_means, pred_vars):\n",
    "    err_xs.append((x, x))\n",
    "    err_ys.append((y - yerr, y + yerr))\n",
    "\n",
    "p.multi_line(err_xs, err_ys, color=(255,0,0,0.15))\n",
    "\n",
    "# p.line([a/100 for a in range(100)], [scale*a/100 for a in range(100)], line_width=3, color=\"blue\")\n",
    "p.line(test_set_flat, pred_means, line_width=2, color=\"red\")\n",
    "\n",
    "p.line(data_input_flat, data_target_flat, line_width=3, color=\"blue\")\n",
    "\n",
    "# p.line(test_set_flat, nn_preds.flatten(), line_width=2, color=\"orange\")\n",
    "\n",
    "# Loss\n",
    "# p.line(range(epochs), epoch_loss, line_width=2, color=\"green\")\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_p = figure(width=500, height=500)\n",
    "\n",
    "# Loss\n",
    "loss_p.line(range(len(epoch_loss)), epoch_loss, line_width=2, color=\"green\")\n",
    "\n",
    "# loss_p.line(range(len(nn_epoch_loss)), nn_epoch_loss, line_width=2, color=\"purple\")\n",
    "\n",
    "show(loss_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
